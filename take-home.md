# Web Scraper Implementation

Harris Data Analytics Team is looking for a research assistant to design and implement a web scraper in Python. We expect that this task should take around 6 hours to complete.

## Specifications

- Use Python 3 to build a web scraper that can crawl text from the following websites:
    - https://harris.uchicago.edu
    - https://www.aps.edu/
    - https://angelhack.com/global-hackathon-series/
- We expect that the third website may pose performance issues for basic Python web scraping frameworks. If your scraper struggles with crawling the third website, please provide us with an explanation. 
- The crawler should be able to scrape at least **50** pages for each website/domain.
- The output should be a file that at least contains urls and text retrieved from them.

## What we are looking for...

**Functionality**   

- Assume that this code will be run on a multi-core `Ubuntu` or `MacOS` machine.
- An user should be able to specify a list of websites to crawl as well as the number of pages to crawl from each website. Additionally, the crawler should not be hard-coded so that it can only crawl the aforementioned websites.
- Given the time that you will be spending on this task, we understand that the scraper may not be fully functioning. We simply ask that you try your best.

**Documention**

- The `README` file should contain:
    - specific instructions on how to run the scraper (if it relies on non-native libraries, be sure to mention it!)
    - a list of what works and what does not work.
- Your source code should be documented, and you may assume that the reader knows Python.

## Due Date

Please complete the task by no later than **1159pm Monday October 21st**.